{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgn49P9aXJKllrl5EfgFfy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vsingh9076/BERT/blob/main/2.%20Data%20Preparation/data_loading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf\n",
        "\n",
        "#for PDF file we need to import PyPDFLoader from langchain framework\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# for CSV file we need to import csv_loader\n",
        "# for Doc we need to import UnstructuredWordDocumentLoader\n",
        "# for Text document we need to import TextLoader\n",
        "#import os to set environment variable\n",
        "\n",
        "filePath = \"/content/A_miniature_version_of_the_course_can_be_found_here__1701743458.pdf\"\n",
        "loader = PyPDFLoader(filePath)\n",
        "#Load document\n",
        "pages = loader.load_and_split()\n",
        "print(pages[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbVuJBiQhDDZ",
        "outputId": "8c80ada7-ef4d-43ea-f348-e9595ff2a36b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-3.17.4-py3-none-any.whl (278 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.17.4\n",
            "GeneratiYe AI Zith LargeLanguage Models.Course Notes : July, 2023\n",
            "Abhi-a5 Kim.3hiGenerative AI, and LLMs specifically, is a General Purpose Technology that is useful for a variety ofapplications. ɝLLMs can be, generally, thought of as a next word prediction modelɝ\n",
            "What is an LLM?LLMs are machine learning models that have learned from massive datasets of humanɫgeneratedcontent, finding statistical patterns to replicate humanɫlike abilities.Foundation models, also known as base models, have been trained on trillions of words for weeks ormonths using extensive compute power. These models have billions of parameters, which representtheir memory and enable sophisticated tasks.Interacting with LLMs differs from traditional programming paradigms. Instead of formalized codesyntax, you provide natural language prompts to the models.When you pass a prompt to the model, it predicts the next words and generates a completion. Thisprocess is known as inference.Part 1What is an LLMɛWhat are the Use Cases for application of LLMsɛWhat are Transformersɛ How was text generation done before Transformersɛ Transformer Architecture.How does a Transformer generate TextɛWhat is a PromptɛGenerative AI Project Life Cycle.How do you preɫtrain Large Language ModelsɛChallenges with preɫtraining LLMs.What is the optimal configuration for preɫtraining LLMsɛWhen is preɫtraining usefulɛPage 1Page 2Page 2Page 4Page 5Page 7Page 8Page 9Page 11Page 12PART 1LLM Pre-TrainingPART 2LLM Fine TuningPART 3RLHF & Application\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"What is an LLM?LLMs are machine learning models that have learned from massive datasets of\n",
        "humanɫgeneratedcontent, finding statistical patterns to replicate humanɫlike abilities.\n",
        "\n",
        "Foundation models,\n",
        "also known as base models, have been trained on trillions of words for weeks ormonths using extensive\n",
        "compute power. These models have billions of parameters, which representtheir memory and enable\n",
        "sophisticated tasks.Interacting with LLMs differs from traditional programming paradigms.\n",
        "\n",
        "\n",
        "Instead of formalized codesyntax, you provide natural language prompts to the models.\n",
        "When you pass a prompt to the model, it predicts the next words and generates a completion.\n",
        "\n",
        "\n",
        "Thisprocess is known as inference.Part 1What is an LLMɛWhat are the Use Cases for application of\n",
        "LLMsɛWhat are Transformersɛ How was text generation done before Transformersɛ Transformer Architecture.\n",
        "How does a Transformer generate TextɛWhat is a PromptɛGenerative AI Project Life Cycle.\n",
        "\n",
        "\n",
        "How do you preɫtrain Large Language ModelsɛChallenges with preɫtraining LLMs.\n",
        "\"\"\"\n",
        "\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\\n\",\n",
        "    chunk_size = 400,\n",
        "    chunk_overlap  = 20\n",
        ")\n",
        "docs = text_splitter.create_documents([text])\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsMItjHxkZ3q",
        "outputId": "f798ad4b-d452-40d6-970a-1fe0ae92dc79"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='What is an LLM?LLMs are machine learning models that have learned from massive datasets of \\nhumanɫgeneratedcontent, finding statistical patterns to replicate humanɫlike abilities.'),\n",
              " Document(page_content='Foundation models, \\nalso known as base models, have been trained on trillions of words for weeks ormonths using extensive \\ncompute power. These models have billions of parameters, which representtheir memory and enable \\nsophisticated tasks.Interacting with LLMs differs from traditional programming paradigms.'),\n",
              " Document(page_content='Instead of formalized codesyntax, you provide natural language prompts to the models.\\nWhen you pass a prompt to the model, it predicts the next words and generates a completion.'),\n",
              " Document(page_content='Thisprocess is known as inference.Part 1What is an LLMɛWhat are the Use Cases for application of \\nLLMsɛWhat are Transformersɛ How was text generation done before Transformersɛ Transformer Architecture.\\nHow does a Transformer generate TextɛWhat is a PromptɛGenerative AI Project Life Cycle.\\n\\n\\nHow do you preɫtrain Large Language ModelsɛChallenges with preɫtraining LLMs.')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AP_ENtqpsUpu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}